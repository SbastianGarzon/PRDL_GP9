{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","authorship_tag":"ABX9TyNUVvZDMcQ78qQPr7Bdp0/G"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"axxDcgq_JUXr","executionInfo":{"status":"ok","timestamp":1705686170346,"user_tz":-60,"elapsed":1757,"user":{"displayName":"Yiyi Lai","userId":"13963626872921425277"}},"outputId":"09d1d035-f556-4509-9b39-923ea8c012bc"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","execution_count":14,"metadata":{"id":"kyQQt4iwI7eS","executionInfo":{"status":"ok","timestamp":1705686173544,"user_tz":-60,"elapsed":236,"user":{"displayName":"Yiyi Lai","userId":"13963626872921425277"}}},"outputs":[],"source":["import numpy as np\n","import os\n","from matplotlib import pyplot as plt\n","from tensorflow import keras\n","import tensorflow as tf\n","from keras.models import Sequential\n","from keras.constraints import max_norm\n","from keras.layers import Layer, Conv2D,Reshape,multiply,Permute, BatchNormalization, AveragePooling2D, Flatten, Dense, Dropout, Activation\n","from keras.layers import Conv1D,DepthwiseConv2D, SeparableConv2D, Attention, GlobalAveragePooling2D,MaxPooling2D\n","from keras import backend as K\n","from keras import layers\n","from sklearn.utils import shuffle\n","from sklearn.model_selection import train_test_split\n","\n","# data process functions\n","\n","def prepro_x(x: np.array, downrate : int) -> np.array:\n","    \"\"\"down sampling from different time points to augmentate data\"\"\"\n","\n","    x_agu = np.zeros((downrate*x.shape[0], x.shape[1], int(x.shape[2]/downrate)))\n","    for k in range(len(x)):\n","        for i in range(downrate):\n","            x_agu[downrate*k + i] = x[k, :, i:downrate*int(x.shape[2]/downrate):downrate]\n","    return x_agu\n","\n","def getdata(downrate : int) -> np.array:\n","    \"\"\"read data, downsample, split train set into train set and validation set\"\"\"\n","\n","    x_train_ori = np.load(r'/content/drive/MyDrive/cross_train_set_nor.npy')\n","    x_test1_ori = np.load(r'/content/drive/MyDrive/cross_test1_set_nor.npy')\n","    x_test2_ori = np.load(r'/content/drive/MyDrive/cross_test2_set_nor.npy')\n","    x_test3_ori = np.load(r'/content/drive/MyDrive/cross_test3_set_nor.npy')\n","\n","    x_train_agu = np.array(prepro_x(x_train_ori, downrate), dtype=np.float32)\n","    x_test1_agu  = np.array(prepro_x(x_test1_ori, downrate), dtype=np.float32)\n","    x_test2_agu  = np.array(prepro_x(x_test2_ori, downrate), dtype=np.float32)\n","    x_test3_agu  = np.array(prepro_x(x_test3_ori, downrate), dtype=np.float32)\n","\n","    y_train0 = np.eye(4)[np.repeat(np.load(r'/content/drive/MyDrive/cross_train_label.npy') - 1, downrate)]\n","    y_test1  = np.eye(4)[np.repeat(np.load(r'/content/drive/MyDrive/cross_test1_label.npy') - 1, downrate)]\n","    y_test2  = np.eye(4)[np.repeat(np.load(r'/content/drive/MyDrive/cross_test2_label.npy') - 1, downrate)]\n","    y_test3  = np.eye(4)[np.repeat(np.load(r'/content/drive/MyDrive/cross_test3_label.npy') - 1, downrate)]\n","\n","    # reshape: numbers, channels, samplingrate, 1\n","    x_train0 = x_train_agu.reshape(x_train_agu.shape[0], x_train_agu.shape[1], x_train_agu.shape[2], 1)\n","    x_test1   = x_test1_agu.reshape(x_test1_agu.shape[0], x_test1_agu.shape[1], x_test1_agu.shape[2], 1)\n","    x_test2   = x_test2_agu.reshape(x_test2_agu.shape[0], x_test2_agu.shape[1], x_test2_agu.shape[2], 1)\n","    x_test3   = x_test3_agu.reshape(x_test3_agu.shape[0], x_test3_agu.shape[1], x_test3_agu.shape[2], 1)\n","\n","    x_train, x_val, y_train, y_val = train_test_split(x_train0, y_train0, test_size=0.2, random_state=42)\n","\n","    return x_train, y_train, x_val, y_val, x_test1, y_test1, x_test2, y_test2, x_test3, y_test3\n","\n","\n","def Model2(input_shape):\n","\n","    #Substituting 2D by 1D convolutions in order to convolved over the temporal dimension first.\n","    # Convolution over the temporal domain\n","    inputs = keras.Input(shape=input_shape, name=\"img\")\n","    x = Conv1D(4, 3, activation=\"relu\", padding=\"same\")(inputs)\n","    x = Conv1D(8, 3, activation=\"relu\", padding=\"same\")(x)\n","    x = BatchNormalization(axis = -1)(x)\n","    block_1_output = MaxPooling2D(3)(x)\n","\n","    x = Conv1D(8, 3, activation=\"relu\", padding=\"same\")(block_1_output)\n","    x = Conv1D(8, 3, activation=\"relu\", padding=\"same\")(x)\n","    x = BatchNormalization(axis = -1)(x)\n","    block_2_output = layers.add([x, block_1_output])\n","\n","    x = Conv1D(8, 3, activation=\"relu\", padding=\"same\")(block_2_output)\n","    x = Conv1D(8, 3, activation=\"relu\", padding=\"same\")(x)\n","    x = BatchNormalization(axis = -1)(x)\n","    block_3_output = layers.add([x, block_2_output])\n","\n","    # Convolution over the spatial domain\n","    x = Conv2D(8, (3,1), activation=\"relu\")(block_3_output)\n","    x = GlobalAveragePooling2D()(x)\n","    x = Dense(64, activation=\"relu\")(x)\n","    x = Dropout(0.5)(x)\n","    outputs = Dense(4,activation = 'softmax',\n","                    #kernel_regularizer = 0.001,\n","                    kernel_constraint = max_norm(0.25))(x)\n","\n","    model = keras.Model(inputs, outputs, name=\"toy_resnet\")\n","    return model\n","\n","\n","def myGenerator(x : np.array, y : np.array, batch_size : int):\n","    \"\"\"set generator for model fitting to load data piece by piece\n","        OOM can be avoided in this way\"\"\"\n","\n","    total_size = len(x)\n","    while 1:\n","        for i in range(total_size // batch_size):\n","            yield x[i*batch_size:(i+1)*batch_size], y[i*batch_size:(i+1)*batch_size]\n","\n","\n","def train_eegnet(X : np.array, Y : np.array, X_val : np.array, Y_val : np.array, batch_size : int, nb_epoch : int) :\n","    \"\"\"Train model, save model, plot training history, save training history\"\"\"\n","\n","    # !!!!!!!!change the path every run!!!!!!!!!! better use a breakpoint here\n","    model_savepath = r'testmodel_re2.tf'\n","    trainloss_savepath = r'trainloss_re2.npy'\n","    validloss_savepath = r'validloss_re2.npy'\n","    checkpoint_path = r'bestmodel_re2.tf'\n","    # Training\n","    checkpoint_dir = os.path.dirname(checkpoint_path)\n","    checkpoint = keras.callbacks.ModelCheckpoint(filepath = checkpoint_path,\n","                                                monitor='val_loss',\n","                                                verbose = 1,\n","                                                save_best_only=True,\n","                                                save_freq= 'epoch')\n","    eegnet_model.compile(loss = 'categorical_crossentropy', metrics = ['categorical_accuracy'],optimizer = 'adam')\n","\n","\n","    history = eegnet_model.fit_generator(myGenerator(X, Y, batch_size),\n","                                        steps_per_epoch = len(X)//(batch_size),\n","                                        validation_data = (X_val, Y_val),\n","                                        epochs     = nb_epoch,\n","                                        verbose    = 1,\n","                                        callbacks  = [checkpoint])\n","\n","    train_loss = history.history['loss']\n","    val_loss = history.history['val_loss']\n","    epochs = range(1, len(train_loss) + 1)\n","\n","    # plot the training and validation loss\n","    plt.plot(epochs, train_loss, '-', color = 'red',label='Training loss')\n","    plt.plot(epochs, val_loss, '--', color ='green',label='Validation loss')\n","    plt.title('Training and validation loss')\n","    plt.xlabel('Epochs')\n","    plt.ylabel('Loss')\n","    plt.legend()\n","    plt.show()\n","\n","    # save the final trained model and history\n","    eegnet_model.save(model_savepath)\n","    np.save(trainloss_savepath, train_loss)\n","    np.save(validloss_savepath, val_loss)\n","\n","    return history, checkpoint_path\n","\n","\n","def predict_eegnet(model_loadpath, x_test, y_test):\n","    \"\"\"predict\"\"\"\n","\n","    model = keras.models.load_model(model_loadpath)\n","    predictions = np.zeros((len(y_test)))\n","\n","    for i in range(len(x_test)):\n","        probability = model.predict(x_test[i:i+1])\n","        predictions[i] = probability.argmax(axis = -1)\n","\n","    label = np.array([one_label.tolist().index(1) for one_label in y_test], dtype = np.float64)\n","    pre_accuracy = np.sum(label == predictions) / len(predictions)\n","    print(predictions)\n","    print(pre_accuracy)\n","\n","    return predictions, pre_accuracy\n","\n","\n","# if __name__ == '__main__':\n","\n","#     os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n","#     print(tf.config.list_physical_devices('GPU'))\n","#     tf.config.optimizer.set_experimental_options({'layout_optimizer': False})\n","#     config = tf.compat.v1.ConfigProto()\n","#     config.gpu_options.per_process_gpu_memory_fraction = 0.5  # programs can only use up to 50% of a given gpu memory\n","#     config.gpu_options.allow_growth = False\n","#     sess = tf.compat.v1.Session(config = config)\n","\n","#     downrate = 18 #downsampling rate\n","#     x_train, y_train, x_val, y_val, x_test1, y_test1, x_test2, y_test2, x_test3, y_test3 = getdata(downrate)\n","#     input_shape = (x_train.shape[1], x_train.shape[2], 1) #inputshape = (channels, time, 1) e.i.(248, 35624, 1)\n","#     K.clear_session()\n","#     # built model\n","#     nb_classes = 4  #classification numbers\n","#     eegnet_model = Model2(input_shape)\n","#     # print model\n","#     eegnet_model.summary()\n","#     # train model\n","#     history, modelpath = train_eegnet(x_train, y_train, x_val, y_val, batch_size = 4, nb_epoch = 100)\n","\n"]},{"cell_type":"code","source":["\n","\n","os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n","print(tf.config.list_physical_devices('GPU'))\n","tf.config.optimizer.set_experimental_options({'layout_optimizer': False})\n","config = tf.compat.v1.ConfigProto()\n","config.gpu_options.per_process_gpu_memory_fraction = 0.5  # programs can only use up to 50% of a given gpu memory\n","config.gpu_options.allow_growth = False\n","sess = tf.compat.v1.Session(config = config)\n","\n","downrate = 8 #downsampling rate\n","x_train, y_train, x_val, y_val, x_test1, y_test1, x_test2, y_test2, x_test3, y_test3 = getdata(downrate)\n","input_shape = (x_train.shape[1], x_train.shape[2], 1) #inputshape = (channels, time, 1) e.i.(248, 35624, 1)\n","K.clear_session()\n","\n"],"metadata":{"id":"tI_rb2iOTvkk","executionInfo":{"status":"aborted","timestamp":1705694617688,"user_tz":-60,"elapsed":2751709,"user":{"displayName":"Yiyi Lai","userId":"13963626872921425277"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# built model\n","nb_classes = 4  #classification numbers\n","eegnet_model = Model2(input_shape)\n","# print model\n","eegnet_model.summary()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qK6wFN0mTzXA","executionInfo":{"status":"ok","timestamp":1705660936693,"user_tz":-60,"elapsed":517,"user":{"displayName":"Yiyi Lai","userId":"13963626872921425277"}},"outputId":"9ba1f195-bbb9-472d-f420-cccc8b3f4d42"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"toy_resnet\"\n","__________________________________________________________________________________________________\n"," Layer (type)                Output Shape                 Param #   Connected to                  \n","==================================================================================================\n"," img (InputLayer)            [(None, 248, 1979, 1)]       0         []                            \n","                                                                                                  \n"," conv1d (Conv1D)             (None, 248, 1979, 4)         16        ['img[0][0]']                 \n","                                                                                                  \n"," conv1d_1 (Conv1D)           (None, 248, 1979, 8)         104       ['conv1d[0][0]']              \n","                                                                                                  \n"," batch_normalization (Batch  (None, 248, 1979, 8)         32        ['conv1d_1[0][0]']            \n"," Normalization)                                                                                   \n","                                                                                                  \n"," max_pooling2d (MaxPooling2  (None, 82, 659, 8)           0         ['batch_normalization[0][0]'] \n"," D)                                                                                               \n","                                                                                                  \n"," conv1d_2 (Conv1D)           (None, 82, 659, 8)           200       ['max_pooling2d[0][0]']       \n","                                                                                                  \n"," conv1d_3 (Conv1D)           (None, 82, 659, 8)           200       ['conv1d_2[0][0]']            \n","                                                                                                  \n"," batch_normalization_1 (Bat  (None, 82, 659, 8)           32        ['conv1d_3[0][0]']            \n"," chNormalization)                                                                                 \n","                                                                                                  \n"," add (Add)                   (None, 82, 659, 8)           0         ['batch_normalization_1[0][0]'\n","                                                                    , 'max_pooling2d[0][0]']      \n","                                                                                                  \n"," conv1d_4 (Conv1D)           (None, 82, 659, 8)           200       ['add[0][0]']                 \n","                                                                                                  \n"," conv1d_5 (Conv1D)           (None, 82, 659, 8)           200       ['conv1d_4[0][0]']            \n","                                                                                                  \n"," batch_normalization_2 (Bat  (None, 82, 659, 8)           32        ['conv1d_5[0][0]']            \n"," chNormalization)                                                                                 \n","                                                                                                  \n"," add_1 (Add)                 (None, 82, 659, 8)           0         ['batch_normalization_2[0][0]'\n","                                                                    , 'add[0][0]']                \n","                                                                                                  \n"," conv2d (Conv2D)             (None, 80, 659, 8)           200       ['add_1[0][0]']               \n","                                                                                                  \n"," global_average_pooling2d (  (None, 8)                    0         ['conv2d[0][0]']              \n"," GlobalAveragePooling2D)                                                                          \n","                                                                                                  \n"," dense (Dense)               (None, 64)                   576       ['global_average_pooling2d[0][\n","                                                                    0]']                          \n","                                                                                                  \n"," dropout (Dropout)           (None, 64)                   0         ['dense[0][0]']               \n","                                                                                                  \n"," dense_1 (Dense)             (None, 4)                    260       ['dropout[0][0]']             \n","                                                                                                  \n","==================================================================================================\n","Total params: 2052 (8.02 KB)\n","Trainable params: 2004 (7.83 KB)\n","Non-trainable params: 48 (192.00 Byte)\n","__________________________________________________________________________________________________\n"]}]},{"cell_type":"code","source":["# train model\n","history, modelpath = train_eegnet(x_train, y_train, x_val, y_val, batch_size = 8, nb_epoch = 100)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"YRlkJ6Z_T1Fs","executionInfo":{"status":"error","timestamp":1705694617686,"user_tz":-60,"elapsed":8364486,"user":{"displayName":"Yiyi Lai","userId":"13963626872921425277"}},"outputId":"564c223e-57cc-471f-d941-97d8025df4cd"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-14-2245881919bc>:116: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n","  history = eegnet_model.fit_generator(myGenerator(X, Y, batch_size),\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n","230/230 [==============================] - ETA: 0s - loss: 0.0979 - categorical_accuracy: 0.9728\n","Epoch 1: val_loss improved from inf to 0.13329, saving model to bestmodel_re2.tf\n","230/230 [==============================] - 171s 712ms/step - loss: 0.0979 - categorical_accuracy: 0.9728 - val_loss: 0.1333 - val_categorical_accuracy: 0.9437\n","Epoch 2/100\n","230/230 [==============================] - ETA: 0s - loss: 0.1078 - categorical_accuracy: 0.9598\n","Epoch 2: val_loss did not improve from 0.13329\n","230/230 [==============================] - 155s 675ms/step - loss: 0.1078 - categorical_accuracy: 0.9598 - val_loss: 0.2944 - val_categorical_accuracy: 0.8571\n","Epoch 3/100\n","230/230 [==============================] - ETA: 0s - loss: 0.1193 - categorical_accuracy: 0.9543\n","Epoch 3: val_loss did not improve from 0.13329\n","230/230 [==============================] - 149s 647ms/step - loss: 0.1193 - categorical_accuracy: 0.9543 - val_loss: 0.5653 - val_categorical_accuracy: 0.7835\n","Epoch 4/100\n","230/230 [==============================] - ETA: 0s - loss: 0.0940 - categorical_accuracy: 0.9630\n","Epoch 4: val_loss did not improve from 0.13329\n","230/230 [==============================] - 177s 772ms/step - loss: 0.0940 - categorical_accuracy: 0.9630 - val_loss: 0.4556 - val_categorical_accuracy: 0.8095\n","Epoch 5/100\n","230/230 [==============================] - ETA: 0s - loss: 0.0885 - categorical_accuracy: 0.9707\n","Epoch 5: val_loss did not improve from 0.13329\n","230/230 [==============================] - 170s 739ms/step - loss: 0.0885 - categorical_accuracy: 0.9707 - val_loss: 0.4368 - val_categorical_accuracy: 0.8355\n","Epoch 6/100\n","230/230 [==============================] - ETA: 0s - loss: 0.1273 - categorical_accuracy: 0.9489\n","Epoch 6: val_loss did not improve from 0.13329\n","230/230 [==============================] - 161s 701ms/step - loss: 0.1273 - categorical_accuracy: 0.9489 - val_loss: 0.1775 - val_categorical_accuracy: 0.9524\n","Epoch 7/100\n","230/230 [==============================] - ETA: 0s - loss: 0.1015 - categorical_accuracy: 0.9652\n","Epoch 7: val_loss improved from 0.13329 to 0.03179, saving model to bestmodel_re2.tf\n","230/230 [==============================] - 125s 543ms/step - loss: 0.1015 - categorical_accuracy: 0.9652 - val_loss: 0.0318 - val_categorical_accuracy: 0.9957\n","Epoch 8/100\n","230/230 [==============================] - ETA: 0s - loss: 0.0890 - categorical_accuracy: 0.9717\n","Epoch 8: val_loss did not improve from 0.03179\n","230/230 [==============================] - 110s 478ms/step - loss: 0.0890 - categorical_accuracy: 0.9717 - val_loss: 0.0654 - val_categorical_accuracy: 0.9697\n","Epoch 9/100\n","230/230 [==============================] - ETA: 0s - loss: 0.1045 - categorical_accuracy: 0.9620\n","Epoch 9: val_loss did not improve from 0.03179\n","230/230 [==============================] - 131s 569ms/step - loss: 0.1045 - categorical_accuracy: 0.9620 - val_loss: 1.0364 - val_categorical_accuracy: 0.6537\n","Epoch 10/100\n","230/230 [==============================] - ETA: 0s - loss: 0.0901 - categorical_accuracy: 0.9674\n","Epoch 10: val_loss did not improve from 0.03179\n","230/230 [==============================] - 125s 543ms/step - loss: 0.0901 - categorical_accuracy: 0.9674 - val_loss: 0.2688 - val_categorical_accuracy: 0.8701\n","Epoch 11/100\n","230/230 [==============================] - ETA: 0s - loss: 0.0842 - categorical_accuracy: 0.9728\n","Epoch 11: val_loss did not improve from 0.03179\n","230/230 [==============================] - 110s 477ms/step - loss: 0.0842 - categorical_accuracy: 0.9728 - val_loss: 0.1379 - val_categorical_accuracy: 0.9524\n","Epoch 12/100\n","230/230 [==============================] - ETA: 0s - loss: 0.0872 - categorical_accuracy: 0.9696\n","Epoch 12: val_loss did not improve from 0.03179\n","230/230 [==============================] - 110s 477ms/step - loss: 0.0872 - categorical_accuracy: 0.9696 - val_loss: 0.2962 - val_categorical_accuracy: 0.8571\n","Epoch 13/100\n","230/230 [==============================] - ETA: 0s - loss: 0.0793 - categorical_accuracy: 0.9717\n","Epoch 13: val_loss did not improve from 0.03179\n","230/230 [==============================] - 109s 476ms/step - loss: 0.0793 - categorical_accuracy: 0.9717 - val_loss: 0.3288 - val_categorical_accuracy: 0.8701\n","Epoch 14/100\n","230/230 [==============================] - ETA: 0s - loss: 0.0943 - categorical_accuracy: 0.9663\n","Epoch 14: val_loss did not improve from 0.03179\n","230/230 [==============================] - 110s 479ms/step - loss: 0.0943 - categorical_accuracy: 0.9663 - val_loss: 0.1629 - val_categorical_accuracy: 0.9221\n","Epoch 15/100\n","230/230 [==============================] - ETA: 0s - loss: 0.0757 - categorical_accuracy: 0.9717\n","Epoch 15: val_loss did not improve from 0.03179\n","230/230 [==============================] - 154s 671ms/step - loss: 0.0757 - categorical_accuracy: 0.9717 - val_loss: 0.1091 - val_categorical_accuracy: 0.9654\n","Epoch 16/100\n","230/230 [==============================] - ETA: 0s - loss: 0.0764 - categorical_accuracy: 0.9783\n","Epoch 16: val_loss did not improve from 0.03179\n","230/230 [==============================] - 109s 475ms/step - loss: 0.0764 - categorical_accuracy: 0.9783 - val_loss: 0.1360 - val_categorical_accuracy: 0.9264\n","Epoch 17/100\n","230/230 [==============================] - ETA: 0s - loss: 0.1172 - categorical_accuracy: 0.9489\n","Epoch 17: val_loss did not improve from 0.03179\n","230/230 [==============================] - 110s 478ms/step - loss: 0.1172 - categorical_accuracy: 0.9489 - val_loss: 0.1101 - val_categorical_accuracy: 0.9481\n","Epoch 18/100\n","230/230 [==============================] - ETA: 0s - loss: 0.0695 - categorical_accuracy: 0.9804\n","Epoch 18: val_loss did not improve from 0.03179\n","230/230 [==============================] - 110s 478ms/step - loss: 0.0695 - categorical_accuracy: 0.9804 - val_loss: 0.0469 - val_categorical_accuracy: 0.9740\n","Epoch 19/100\n","230/230 [==============================] - ETA: 0s - loss: 0.0708 - categorical_accuracy: 0.9761\n","Epoch 19: val_loss did not improve from 0.03179\n","230/230 [==============================] - 113s 491ms/step - loss: 0.0708 - categorical_accuracy: 0.9761 - val_loss: 0.2885 - val_categorical_accuracy: 0.8831\n","Epoch 20/100\n","230/230 [==============================] - ETA: 0s - loss: 0.1024 - categorical_accuracy: 0.9663\n","Epoch 20: val_loss did not improve from 0.03179\n","230/230 [==============================] - 110s 476ms/step - loss: 0.1024 - categorical_accuracy: 0.9663 - val_loss: 0.3975 - val_categorical_accuracy: 0.8701\n","Epoch 21/100\n","230/230 [==============================] - ETA: 0s - loss: 0.0890 - categorical_accuracy: 0.9674\n","Epoch 21: val_loss did not improve from 0.03179\n","230/230 [==============================] - 109s 476ms/step - loss: 0.0890 - categorical_accuracy: 0.9674 - val_loss: 0.1059 - val_categorical_accuracy: 0.9610\n","Epoch 22/100\n","230/230 [==============================] - ETA: 0s - loss: 0.0586 - categorical_accuracy: 0.9793\n","Epoch 22: val_loss did not improve from 0.03179\n","230/230 [==============================] - 109s 476ms/step - loss: 0.0586 - categorical_accuracy: 0.9793 - val_loss: 1.5063 - val_categorical_accuracy: 0.6061\n","Epoch 23/100\n","230/230 [==============================] - ETA: 0s - loss: 0.0850 - categorical_accuracy: 0.9696\n","Epoch 23: val_loss did not improve from 0.03179\n","230/230 [==============================] - 110s 479ms/step - loss: 0.0850 - categorical_accuracy: 0.9696 - val_loss: 0.0361 - val_categorical_accuracy: 1.0000\n","Epoch 24/100\n","230/230 [==============================] - ETA: 0s - loss: 0.0644 - categorical_accuracy: 0.9761\n","Epoch 24: val_loss did not improve from 0.03179\n","230/230 [==============================] - 110s 477ms/step - loss: 0.0644 - categorical_accuracy: 0.9761 - val_loss: 0.0585 - val_categorical_accuracy: 0.9740\n","Epoch 25/100\n","230/230 [==============================] - ETA: 0s - loss: 0.0669 - categorical_accuracy: 0.9804\n","Epoch 25: val_loss did not improve from 0.03179\n","230/230 [==============================] - 109s 476ms/step - loss: 0.0669 - categorical_accuracy: 0.9804 - val_loss: 0.2669 - val_categorical_accuracy: 0.8918\n","Epoch 26/100\n","230/230 [==============================] - ETA: 0s - loss: 0.0815 - categorical_accuracy: 0.9717\n","Epoch 26: val_loss did not improve from 0.03179\n","230/230 [==============================] - 108s 471ms/step - loss: 0.0815 - categorical_accuracy: 0.9717 - val_loss: 0.2875 - val_categorical_accuracy: 0.8961\n","Epoch 27/100\n","230/230 [==============================] - ETA: 0s - loss: 0.0709 - categorical_accuracy: 0.9783\n","Epoch 27: val_loss improved from 0.03179 to 0.02318, saving model to bestmodel_re2.tf\n","230/230 [==============================] - 113s 490ms/step - loss: 0.0709 - categorical_accuracy: 0.9783 - val_loss: 0.0232 - val_categorical_accuracy: 1.0000\n","Epoch 28/100\n","230/230 [==============================] - ETA: 0s - loss: 0.0549 - categorical_accuracy: 0.9815\n","Epoch 28: val_loss did not improve from 0.02318\n","230/230 [==============================] - 110s 477ms/step - loss: 0.0549 - categorical_accuracy: 0.9815 - val_loss: 0.1053 - val_categorical_accuracy: 0.9610\n","Epoch 29/100\n","230/230 [==============================] - ETA: 0s - loss: 0.0708 - categorical_accuracy: 0.9707\n","Epoch 29: val_loss did not improve from 0.02318\n","230/230 [==============================] - 108s 469ms/step - loss: 0.0708 - categorical_accuracy: 0.9707 - val_loss: 0.0246 - val_categorical_accuracy: 1.0000\n","Epoch 30/100\n","230/230 [==============================] - ETA: 0s - loss: 0.0515 - categorical_accuracy: 0.9826\n","Epoch 30: val_loss did not improve from 0.02318\n","230/230 [==============================] - 112s 489ms/step - loss: 0.0515 - categorical_accuracy: 0.9826 - val_loss: 0.0553 - val_categorical_accuracy: 0.9740\n","Epoch 31/100\n","230/230 [==============================] - ETA: 0s - loss: 0.0644 - categorical_accuracy: 0.9761\n","Epoch 31: val_loss did not improve from 0.02318\n","230/230 [==============================] - 108s 470ms/step - loss: 0.0644 - categorical_accuracy: 0.9761 - val_loss: 0.1035 - val_categorical_accuracy: 0.9697\n","Epoch 32/100\n","230/230 [==============================] - ETA: 0s - loss: 0.0674 - categorical_accuracy: 0.9793\n","Epoch 32: val_loss did not improve from 0.02318\n","230/230 [==============================] - 108s 468ms/step - loss: 0.0674 - categorical_accuracy: 0.9793 - val_loss: 0.0790 - val_categorical_accuracy: 0.9437\n","Epoch 33/100\n","230/230 [==============================] - ETA: 0s - loss: 0.0626 - categorical_accuracy: 0.9772\n","Epoch 33: val_loss did not improve from 0.02318\n","230/230 [==============================] - 108s 468ms/step - loss: 0.0626 - categorical_accuracy: 0.9772 - val_loss: 0.0827 - val_categorical_accuracy: 0.9481\n","Epoch 34/100\n","230/230 [==============================] - ETA: 0s - loss: 0.0759 - categorical_accuracy: 0.9717\n","Epoch 34: val_loss did not improve from 0.02318\n","230/230 [==============================] - 109s 472ms/step - loss: 0.0759 - categorical_accuracy: 0.9717 - val_loss: 0.0717 - val_categorical_accuracy: 0.9654\n","Epoch 35/100\n","230/230 [==============================] - ETA: 0s - loss: 0.0623 - categorical_accuracy: 0.9750\n","Epoch 35: val_loss improved from 0.02318 to 0.01151, saving model to bestmodel_re2.tf\n","230/230 [==============================] - 111s 481ms/step - loss: 0.0623 - categorical_accuracy: 0.9750 - val_loss: 0.0115 - val_categorical_accuracy: 1.0000\n","Epoch 36/100\n","230/230 [==============================] - ETA: 0s - loss: 0.0546 - categorical_accuracy: 0.9837\n","Epoch 36: val_loss did not improve from 0.01151\n","230/230 [==============================] - 108s 470ms/step - loss: 0.0546 - categorical_accuracy: 0.9837 - val_loss: 0.0163 - val_categorical_accuracy: 1.0000\n","Epoch 37/100\n","230/230 [==============================] - ETA: 0s - loss: 0.0695 - categorical_accuracy: 0.9783\n","Epoch 37: val_loss did not improve from 0.01151\n","230/230 [==============================] - 108s 471ms/step - loss: 0.0695 - categorical_accuracy: 0.9783 - val_loss: 0.0121 - val_categorical_accuracy: 1.0000\n","Epoch 38/100\n","230/230 [==============================] - ETA: 0s - loss: 0.0567 - categorical_accuracy: 0.9815\n","Epoch 38: val_loss did not improve from 0.01151\n","230/230 [==============================] - 108s 470ms/step - loss: 0.0567 - categorical_accuracy: 0.9815 - val_loss: 0.0547 - val_categorical_accuracy: 0.9740\n","Epoch 39/100\n","230/230 [==============================] - ETA: 0s - loss: 0.0536 - categorical_accuracy: 0.9826\n","Epoch 39: val_loss did not improve from 0.01151\n","230/230 [==============================] - 109s 472ms/step - loss: 0.0536 - categorical_accuracy: 0.9826 - val_loss: 0.2083 - val_categorical_accuracy: 0.8961\n","Epoch 40/100\n","230/230 [==============================] - ETA: 0s - loss: 0.0497 - categorical_accuracy: 0.9826\n","Epoch 40: val_loss did not improve from 0.01151\n","230/230 [==============================] - 108s 472ms/step - loss: 0.0497 - categorical_accuracy: 0.9826 - val_loss: 0.0721 - val_categorical_accuracy: 0.9740\n","Epoch 41/100\n","230/230 [==============================] - ETA: 0s - loss: 0.0437 - categorical_accuracy: 0.9880\n","Epoch 41: val_loss improved from 0.01151 to 0.00692, saving model to bestmodel_re2.tf\n","230/230 [==============================] - 113s 491ms/step - loss: 0.0437 - categorical_accuracy: 0.9880 - val_loss: 0.0069 - val_categorical_accuracy: 1.0000\n","Epoch 42/100\n","230/230 [==============================] - ETA: 0s - loss: 0.0509 - categorical_accuracy: 0.9804\n","Epoch 42: val_loss did not improve from 0.00692\n","230/230 [==============================] - 108s 468ms/step - loss: 0.0509 - categorical_accuracy: 0.9804 - val_loss: 0.0488 - val_categorical_accuracy: 0.9913\n","Epoch 43/100\n","230/230 [==============================] - ETA: 0s - loss: 0.0366 - categorical_accuracy: 0.9891\n","Epoch 43: val_loss did not improve from 0.00692\n","230/230 [==============================] - 109s 473ms/step - loss: 0.0366 - categorical_accuracy: 0.9891 - val_loss: 0.0221 - val_categorical_accuracy: 1.0000\n","Epoch 44/100\n","230/230 [==============================] - ETA: 0s - loss: 0.0880 - categorical_accuracy: 0.9717\n","Epoch 44: val_loss did not improve from 0.00692\n","230/230 [==============================] - 108s 471ms/step - loss: 0.0880 - categorical_accuracy: 0.9717 - val_loss: 0.0306 - val_categorical_accuracy: 0.9870\n","Epoch 45/100\n","230/230 [==============================] - ETA: 0s - loss: 0.0722 - categorical_accuracy: 0.9761\n","Epoch 45: val_loss did not improve from 0.00692\n","230/230 [==============================] - 108s 469ms/step - loss: 0.0722 - categorical_accuracy: 0.9761 - val_loss: 0.0610 - val_categorical_accuracy: 0.9740\n","Epoch 46/100\n","230/230 [==============================] - ETA: 0s - loss: 0.0413 - categorical_accuracy: 0.9902\n","Epoch 46: val_loss did not improve from 0.00692\n","230/230 [==============================] - 109s 476ms/step - loss: 0.0413 - categorical_accuracy: 0.9902 - val_loss: 0.0250 - val_categorical_accuracy: 1.0000\n","Epoch 47/100\n","230/230 [==============================] - ETA: 0s - loss: 0.0394 - categorical_accuracy: 0.9870\n","Epoch 47: val_loss did not improve from 0.00692\n","230/230 [==============================] - 108s 472ms/step - loss: 0.0394 - categorical_accuracy: 0.9870 - val_loss: 0.0349 - val_categorical_accuracy: 0.9957\n","Epoch 48/100\n","230/230 [==============================] - ETA: 0s - loss: 0.0280 - categorical_accuracy: 0.9946\n","Epoch 48: val_loss did not improve from 0.00692\n","230/230 [==============================] - 109s 475ms/step - loss: 0.0280 - categorical_accuracy: 0.9946 - val_loss: 0.0643 - val_categorical_accuracy: 0.9740\n","Epoch 49/100\n","230/230 [==============================] - ETA: 0s - loss: 0.0618 - categorical_accuracy: 0.9804\n","Epoch 49: val_loss did not improve from 0.00692\n","230/230 [==============================] - 108s 470ms/step - loss: 0.0618 - categorical_accuracy: 0.9804 - val_loss: 0.2933 - val_categorical_accuracy: 0.9134\n","Epoch 50/100\n","230/230 [==============================] - ETA: 0s - loss: 0.1049 - categorical_accuracy: 0.9554\n","Epoch 50: val_loss did not improve from 0.00692\n","230/230 [==============================] - 108s 470ms/step - loss: 0.1049 - categorical_accuracy: 0.9554 - val_loss: 0.0977 - val_categorical_accuracy: 0.9567\n","Epoch 51/100\n","230/230 [==============================] - ETA: 0s - loss: 0.0671 - categorical_accuracy: 0.9804\n","Epoch 51: val_loss did not improve from 0.00692\n","230/230 [==============================] - 108s 470ms/step - loss: 0.0671 - categorical_accuracy: 0.9804 - val_loss: 0.0106 - val_categorical_accuracy: 1.0000\n","Epoch 52/100\n","230/230 [==============================] - ETA: 0s - loss: 0.0570 - categorical_accuracy: 0.9826\n","Epoch 52: val_loss did not improve from 0.00692\n","230/230 [==============================] - 110s 479ms/step - loss: 0.0570 - categorical_accuracy: 0.9826 - val_loss: 0.0357 - val_categorical_accuracy: 0.9740\n","Epoch 53/100\n","230/230 [==============================] - ETA: 0s - loss: 0.0336 - categorical_accuracy: 0.9913\n","Epoch 53: val_loss improved from 0.00692 to 0.00668, saving model to bestmodel_re2.tf\n","230/230 [==============================] - 111s 481ms/step - loss: 0.0336 - categorical_accuracy: 0.9913 - val_loss: 0.0067 - val_categorical_accuracy: 1.0000\n","Epoch 54/100\n","230/230 [==============================] - ETA: 0s - loss: 0.0379 - categorical_accuracy: 0.9913\n","Epoch 54: val_loss did not improve from 0.00668\n","230/230 [==============================] - 108s 471ms/step - loss: 0.0379 - categorical_accuracy: 0.9913 - val_loss: 0.0684 - val_categorical_accuracy: 0.9740\n","Epoch 55/100\n","230/230 [==============================] - ETA: 0s - loss: 0.0323 - categorical_accuracy: 0.9891\n","Epoch 55: val_loss did not improve from 0.00668\n","230/230 [==============================] - 107s 467ms/step - loss: 0.0323 - categorical_accuracy: 0.9891 - val_loss: 0.0330 - val_categorical_accuracy: 0.9740\n","Epoch 56/100\n","230/230 [==============================] - ETA: 0s - loss: 0.0357 - categorical_accuracy: 0.9902\n","Epoch 56: val_loss did not improve from 0.00668\n","230/230 [==============================] - 107s 466ms/step - loss: 0.0357 - categorical_accuracy: 0.9902 - val_loss: 0.1043 - val_categorical_accuracy: 0.9697\n","Epoch 57/100\n","230/230 [==============================] - ETA: 0s - loss: 0.0452 - categorical_accuracy: 0.9837\n","Epoch 57: val_loss did not improve from 0.00668\n","230/230 [==============================] - 109s 474ms/step - loss: 0.0452 - categorical_accuracy: 0.9837 - val_loss: 0.0423 - val_categorical_accuracy: 0.9740\n","Epoch 58/100\n","230/230 [==============================] - ETA: 0s - loss: 0.0497 - categorical_accuracy: 0.9826\n","Epoch 58: val_loss improved from 0.00668 to 0.00653, saving model to bestmodel_re2.tf\n","230/230 [==============================] - 111s 484ms/step - loss: 0.0497 - categorical_accuracy: 0.9826 - val_loss: 0.0065 - val_categorical_accuracy: 1.0000\n","Epoch 59/100\n","230/230 [==============================] - ETA: 0s - loss: 0.0483 - categorical_accuracy: 0.9848\n","Epoch 59: val_loss did not improve from 0.00653\n","230/230 [==============================] - 107s 467ms/step - loss: 0.0483 - categorical_accuracy: 0.9848 - val_loss: 0.0113 - val_categorical_accuracy: 1.0000\n","Epoch 60/100\n","230/230 [==============================] - ETA: 0s - loss: 0.0520 - categorical_accuracy: 0.9783\n","Epoch 60: val_loss did not improve from 0.00653\n","230/230 [==============================] - 107s 467ms/step - loss: 0.0520 - categorical_accuracy: 0.9783 - val_loss: 0.0235 - val_categorical_accuracy: 0.9913\n","Epoch 61/100\n","230/230 [==============================] - ETA: 0s - loss: 0.0443 - categorical_accuracy: 0.9859\n","Epoch 61: val_loss did not improve from 0.00653\n","230/230 [==============================] - 109s 475ms/step - loss: 0.0443 - categorical_accuracy: 0.9859 - val_loss: 0.0406 - val_categorical_accuracy: 0.9740\n","Epoch 62/100\n","230/230 [==============================] - ETA: 0s - loss: 0.0335 - categorical_accuracy: 0.9902\n","Epoch 62: val_loss improved from 0.00653 to 0.00454, saving model to bestmodel_re2.tf\n","230/230 [==============================] - 111s 481ms/step - loss: 0.0335 - categorical_accuracy: 0.9902 - val_loss: 0.0045 - val_categorical_accuracy: 1.0000\n","Epoch 63/100\n","230/230 [==============================] - ETA: 0s - loss: 0.0564 - categorical_accuracy: 0.9815\n","Epoch 63: val_loss did not improve from 0.00454\n","230/230 [==============================] - 109s 473ms/step - loss: 0.0564 - categorical_accuracy: 0.9815 - val_loss: 0.3373 - val_categorical_accuracy: 0.8745\n","Epoch 64/100\n","230/230 [==============================] - ETA: 0s - loss: 0.0316 - categorical_accuracy: 0.9924\n","Epoch 64: val_loss did not improve from 0.00454\n","230/230 [==============================] - 112s 489ms/step - loss: 0.0316 - categorical_accuracy: 0.9924 - val_loss: 0.3098 - val_categorical_accuracy: 0.8831\n","Epoch 65/100\n","230/230 [==============================] - ETA: 0s - loss: 0.0631 - categorical_accuracy: 0.9848\n","Epoch 65: val_loss did not improve from 0.00454\n","230/230 [==============================] - 108s 471ms/step - loss: 0.0631 - categorical_accuracy: 0.9848 - val_loss: 0.0860 - val_categorical_accuracy: 0.9437\n","Epoch 66/100\n","230/230 [==============================] - ETA: 0s - loss: 0.0400 - categorical_accuracy: 0.9880\n","Epoch 66: val_loss did not improve from 0.00454\n","230/230 [==============================] - 109s 473ms/step - loss: 0.0400 - categorical_accuracy: 0.9880 - val_loss: 0.0357 - val_categorical_accuracy: 0.9913\n","Epoch 67/100\n","230/230 [==============================] - ETA: 0s - loss: 0.0729 - categorical_accuracy: 0.9783\n","Epoch 67: val_loss did not improve from 0.00454\n","230/230 [==============================] - 108s 472ms/step - loss: 0.0729 - categorical_accuracy: 0.9783 - val_loss: 0.1103 - val_categorical_accuracy: 0.9481\n","Epoch 68/100\n","230/230 [==============================] - ETA: 0s - loss: 0.0371 - categorical_accuracy: 0.9891\n","Epoch 68: val_loss did not improve from 0.00454\n","230/230 [==============================] - 108s 470ms/step - loss: 0.0371 - categorical_accuracy: 0.9891 - val_loss: 0.0065 - val_categorical_accuracy: 1.0000\n","Epoch 69/100\n","230/230 [==============================] - ETA: 0s - loss: 0.0341 - categorical_accuracy: 0.9848\n","Epoch 69: val_loss did not improve from 0.00454\n","230/230 [==============================] - 107s 467ms/step - loss: 0.0341 - categorical_accuracy: 0.9848 - val_loss: 0.0310 - val_categorical_accuracy: 0.9957\n","Epoch 70/100\n","230/230 [==============================] - ETA: 0s - loss: 0.0841 - categorical_accuracy: 0.9739\n","Epoch 70: val_loss did not improve from 0.00454\n","230/230 [==============================] - 110s 477ms/step - loss: 0.0841 - categorical_accuracy: 0.9739 - val_loss: 0.0207 - val_categorical_accuracy: 0.9957\n","Epoch 71/100\n","230/230 [==============================] - ETA: 0s - loss: 0.0358 - categorical_accuracy: 0.9880\n","Epoch 71: val_loss did not improve from 0.00454\n","230/230 [==============================] - 108s 471ms/step - loss: 0.0358 - categorical_accuracy: 0.9880 - val_loss: 0.0087 - val_categorical_accuracy: 1.0000\n","Epoch 72/100\n","230/230 [==============================] - ETA: 0s - loss: 0.0251 - categorical_accuracy: 0.9946\n","Epoch 72: val_loss did not improve from 0.00454\n","230/230 [==============================] - 108s 469ms/step - loss: 0.0251 - categorical_accuracy: 0.9946 - val_loss: 0.0064 - val_categorical_accuracy: 1.0000\n","Epoch 73/100\n","188/230 [=======================>......] - ETA: 17s - loss: 0.0190 - categorical_accuracy: 0.9960"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-16-d90bba6b2bc5>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# train model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mhistory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodelpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_eegnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-14-2245881919bc>\u001b[0m in \u001b[0;36mtrain_eegnet\u001b[0;34m(X, Y, X_val, Y_val, batch_size, nb_epoch)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m     history = eegnet_model.fit_generator(myGenerator(X, Y, batch_size),\n\u001b[0m\u001b[1;32m    117\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m                                         \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   2911\u001b[0m             \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2912\u001b[0m         )\n\u001b[0;32m-> 2913\u001b[0;31m         return self.fit(\n\u001b[0m\u001b[1;32m   2914\u001b[0m             \u001b[0mgenerator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2915\u001b[0m             \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1805\u001b[0m                         ):\n\u001b[1;32m   1806\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1807\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1808\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1809\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    831\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 832\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    833\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    834\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    866\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    867\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 868\u001b[0;31m       return tracing_compilation.call_function(\n\u001b[0m\u001b[1;32m    869\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m       )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0mbound_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0mflat_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m   return function._call_flat(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    140\u001b[0m       \u001b[0mflat_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m   )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1321\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1322\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1325\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0mflat_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    252\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1484\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1485\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1486\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1487\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1488\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["    # predict\n","    modelpath = r'bestmodel_re2.tf'\n","    y_pre1, acc1 = predict_eegnet(modelpath, x_test1, y_test1)\n","    y_pre2, acc2 = predict_eegnet(modelpath, x_test2, y_test2)\n","    y_pre3, acc3 = predict_eegnet(modelpath, x_test3, y_test3)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CcY0PtGyJTb8","executionInfo":{"status":"ok","timestamp":1705694742732,"user_tz":-60,"elapsed":118343,"user":{"displayName":"Yiyi Lai","userId":"13963626872921425277"}},"outputId":"82dbc695-39a4-4f56-d795-be36ae9c80cd"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 410ms/step\n","1/1 [==============================] - 0s 87ms/step\n","1/1 [==============================] - 0s 74ms/step\n","1/1 [==============================] - 0s 78ms/step\n","1/1 [==============================] - 0s 75ms/step\n","1/1 [==============================] - 0s 86ms/step\n","1/1 [==============================] - 0s 74ms/step\n","1/1 [==============================] - 0s 72ms/step\n","1/1 [==============================] - 0s 73ms/step\n","1/1 [==============================] - 0s 70ms/step\n","1/1 [==============================] - 0s 101ms/step\n","1/1 [==============================] - 0s 86ms/step\n","1/1 [==============================] - 0s 74ms/step\n","1/1 [==============================] - 0s 82ms/step\n","1/1 [==============================] - 0s 82ms/step\n","1/1 [==============================] - 0s 79ms/step\n","1/1 [==============================] - 0s 85ms/step\n","1/1 [==============================] - 0s 91ms/step\n","1/1 [==============================] - 0s 75ms/step\n","1/1 [==============================] - 0s 76ms/step\n","1/1 [==============================] - 0s 78ms/step\n","1/1 [==============================] - 0s 90ms/step\n","1/1 [==============================] - 0s 94ms/step\n","1/1 [==============================] - 0s 84ms/step\n","1/1 [==============================] - 0s 75ms/step\n","1/1 [==============================] - 0s 79ms/step\n","1/1 [==============================] - 0s 71ms/step\n","1/1 [==============================] - 0s 76ms/step\n","1/1 [==============================] - 0s 80ms/step\n","1/1 [==============================] - 0s 76ms/step\n","1/1 [==============================] - 0s 74ms/step\n","1/1 [==============================] - 0s 75ms/step\n","1/1 [==============================] - 0s 70ms/step\n","1/1 [==============================] - 0s 69ms/step\n","1/1 [==============================] - 0s 65ms/step\n","1/1 [==============================] - 0s 66ms/step\n","1/1 [==============================] - 0s 68ms/step\n","1/1 [==============================] - 0s 65ms/step\n","1/1 [==============================] - 0s 69ms/step\n","1/1 [==============================] - 0s 68ms/step\n","1/1 [==============================] - 0s 69ms/step\n","1/1 [==============================] - 0s 66ms/step\n","1/1 [==============================] - 0s 65ms/step\n","1/1 [==============================] - 0s 68ms/step\n","1/1 [==============================] - 0s 65ms/step\n","1/1 [==============================] - 0s 63ms/step\n","1/1 [==============================] - 0s 62ms/step\n","1/1 [==============================] - 0s 66ms/step\n","1/1 [==============================] - 0s 68ms/step\n","1/1 [==============================] - 0s 71ms/step\n","1/1 [==============================] - 0s 66ms/step\n","1/1 [==============================] - 0s 69ms/step\n","1/1 [==============================] - 0s 66ms/step\n","1/1 [==============================] - 0s 64ms/step\n","1/1 [==============================] - 0s 65ms/step\n","1/1 [==============================] - 0s 69ms/step\n","1/1 [==============================] - 0s 67ms/step\n","1/1 [==============================] - 0s 65ms/step\n","1/1 [==============================] - 0s 70ms/step\n","1/1 [==============================] - 0s 70ms/step\n","1/1 [==============================] - 0s 73ms/step\n","1/1 [==============================] - 0s 69ms/step\n","1/1 [==============================] - 0s 70ms/step\n","1/1 [==============================] - 0s 70ms/step\n","1/1 [==============================] - 0s 68ms/step\n","1/1 [==============================] - 0s 65ms/step\n","1/1 [==============================] - 0s 66ms/step\n","1/1 [==============================] - 0s 71ms/step\n","1/1 [==============================] - 0s 71ms/step\n","1/1 [==============================] - 0s 83ms/step\n","1/1 [==============================] - 0s 77ms/step\n","1/1 [==============================] - 0s 75ms/step\n","1/1 [==============================] - 0s 76ms/step\n","1/1 [==============================] - 0s 84ms/step\n","1/1 [==============================] - 0s 77ms/step\n","1/1 [==============================] - 0s 66ms/step\n","1/1 [==============================] - 0s 71ms/step\n","1/1 [==============================] - 0s 70ms/step\n","1/1 [==============================] - 0s 70ms/step\n","1/1 [==============================] - 0s 68ms/step\n","1/1 [==============================] - 0s 72ms/step\n","1/1 [==============================] - 0s 68ms/step\n","1/1 [==============================] - 0s 77ms/step\n","1/1 [==============================] - 0s 67ms/step\n","1/1 [==============================] - 0s 71ms/step\n","1/1 [==============================] - 0s 77ms/step\n","1/1 [==============================] - 0s 70ms/step\n","1/1 [==============================] - 0s 80ms/step\n","1/1 [==============================] - 0s 76ms/step\n","1/1 [==============================] - 0s 67ms/step\n","1/1 [==============================] - 0s 84ms/step\n","1/1 [==============================] - 0s 77ms/step\n","1/1 [==============================] - 0s 80ms/step\n","1/1 [==============================] - 0s 73ms/step\n","1/1 [==============================] - 0s 76ms/step\n","1/1 [==============================] - 0s 68ms/step\n","1/1 [==============================] - 0s 65ms/step\n","1/1 [==============================] - 0s 67ms/step\n","1/1 [==============================] - 0s 68ms/step\n","1/1 [==============================] - 0s 66ms/step\n","1/1 [==============================] - 0s 69ms/step\n","1/1 [==============================] - 0s 63ms/step\n","1/1 [==============================] - 0s 68ms/step\n","1/1 [==============================] - 0s 70ms/step\n","1/1 [==============================] - 0s 67ms/step\n","1/1 [==============================] - 0s 69ms/step\n","1/1 [==============================] - 0s 64ms/step\n","1/1 [==============================] - 0s 72ms/step\n","1/1 [==============================] - 0s 69ms/step\n","1/1 [==============================] - 0s 67ms/step\n","1/1 [==============================] - 0s 64ms/step\n","1/1 [==============================] - 0s 72ms/step\n","1/1 [==============================] - 0s 68ms/step\n","1/1 [==============================] - 0s 67ms/step\n","1/1 [==============================] - 0s 66ms/step\n","1/1 [==============================] - 0s 68ms/step\n","1/1 [==============================] - 0s 68ms/step\n","1/1 [==============================] - 0s 69ms/step\n","1/1 [==============================] - 0s 67ms/step\n","1/1 [==============================] - 0s 70ms/step\n","1/1 [==============================] - 0s 65ms/step\n","1/1 [==============================] - 0s 70ms/step\n","1/1 [==============================] - 0s 69ms/step\n","1/1 [==============================] - 0s 68ms/step\n","1/1 [==============================] - 0s 68ms/step\n","1/1 [==============================] - 0s 68ms/step\n","1/1 [==============================] - 0s 70ms/step\n","1/1 [==============================] - 0s 67ms/step\n","1/1 [==============================] - 0s 69ms/step\n","1/1 [==============================] - 0s 63ms/step\n","1/1 [==============================] - 0s 67ms/step\n","1/1 [==============================] - 0s 67ms/step\n","1/1 [==============================] - 0s 70ms/step\n","1/1 [==============================] - 0s 70ms/step\n","1/1 [==============================] - 0s 68ms/step\n","1/1 [==============================] - 0s 69ms/step\n","1/1 [==============================] - 0s 69ms/step\n","1/1 [==============================] - 0s 70ms/step\n","1/1 [==============================] - 0s 64ms/step\n","1/1 [==============================] - 0s 63ms/step\n","1/1 [==============================] - 0s 64ms/step\n","1/1 [==============================] - 0s 66ms/step\n","1/1 [==============================] - 0s 65ms/step\n","1/1 [==============================] - 0s 70ms/step\n","1/1 [==============================] - 0s 69ms/step\n","1/1 [==============================] - 0s 68ms/step\n","1/1 [==============================] - 0s 65ms/step\n","1/1 [==============================] - 0s 71ms/step\n","1/1 [==============================] - 0s 66ms/step\n","1/1 [==============================] - 0s 66ms/step\n","1/1 [==============================] - 0s 67ms/step\n","1/1 [==============================] - 0s 71ms/step\n","1/1 [==============================] - 0s 66ms/step\n","1/1 [==============================] - 0s 66ms/step\n","1/1 [==============================] - 0s 70ms/step\n","1/1 [==============================] - 0s 68ms/step\n","1/1 [==============================] - 0s 70ms/step\n","1/1 [==============================] - 0s 61ms/step\n","1/1 [==============================] - 0s 68ms/step\n","1/1 [==============================] - 0s 69ms/step\n","1/1 [==============================] - 0s 64ms/step\n","1/1 [==============================] - 0s 68ms/step\n","1/1 [==============================] - 0s 66ms/step\n","1/1 [==============================] - 0s 64ms/step\n","1/1 [==============================] - 0s 68ms/step\n","1/1 [==============================] - 0s 63ms/step\n","1/1 [==============================] - 0s 65ms/step\n","1/1 [==============================] - 0s 68ms/step\n","1/1 [==============================] - 0s 72ms/step\n","1/1 [==============================] - 0s 68ms/step\n","1/1 [==============================] - 0s 70ms/step\n","1/1 [==============================] - 0s 67ms/step\n","1/1 [==============================] - 0s 71ms/step\n","1/1 [==============================] - 0s 67ms/step\n","1/1 [==============================] - 0s 65ms/step\n","1/1 [==============================] - 0s 75ms/step\n","1/1 [==============================] - 0s 74ms/step\n","1/1 [==============================] - 0s 73ms/step\n","1/1 [==============================] - 0s 73ms/step\n","1/1 [==============================] - 0s 72ms/step\n","1/1 [==============================] - 0s 68ms/step\n","1/1 [==============================] - 0s 69ms/step\n","1/1 [==============================] - 0s 69ms/step\n","1/1 [==============================] - 0s 68ms/step\n","1/1 [==============================] - 0s 81ms/step\n","1/1 [==============================] - 0s 70ms/step\n","1/1 [==============================] - 0s 70ms/step\n","1/1 [==============================] - 0s 72ms/step\n","1/1 [==============================] - 0s 73ms/step\n","1/1 [==============================] - 0s 67ms/step\n","1/1 [==============================] - 0s 75ms/step\n","1/1 [==============================] - 0s 70ms/step\n","1/1 [==============================] - 0s 75ms/step\n","1/1 [==============================] - 0s 72ms/step\n","1/1 [==============================] - 0s 66ms/step\n","1/1 [==============================] - 0s 76ms/step\n","1/1 [==============================] - 0s 68ms/step\n","1/1 [==============================] - 0s 67ms/step\n","1/1 [==============================] - 0s 72ms/step\n","1/1 [==============================] - 0s 70ms/step\n","1/1 [==============================] - 0s 74ms/step\n","1/1 [==============================] - 0s 69ms/step\n","1/1 [==============================] - 0s 70ms/step\n","1/1 [==============================] - 0s 68ms/step\n","1/1 [==============================] - 0s 68ms/step\n","1/1 [==============================] - 0s 68ms/step\n","1/1 [==============================] - 0s 66ms/step\n","1/1 [==============================] - 0s 62ms/step\n","1/1 [==============================] - 0s 68ms/step\n","1/1 [==============================] - 0s 64ms/step\n","1/1 [==============================] - 0s 65ms/step\n","1/1 [==============================] - 0s 65ms/step\n","1/1 [==============================] - 0s 70ms/step\n","1/1 [==============================] - 0s 68ms/step\n","1/1 [==============================] - 0s 70ms/step\n","1/1 [==============================] - 0s 67ms/step\n","1/1 [==============================] - 0s 67ms/step\n","1/1 [==============================] - 0s 66ms/step\n","1/1 [==============================] - 0s 71ms/step\n","1/1 [==============================] - 0s 66ms/step\n","1/1 [==============================] - 0s 62ms/step\n","1/1 [==============================] - 0s 69ms/step\n","1/1 [==============================] - 0s 70ms/step\n","1/1 [==============================] - 0s 66ms/step\n","1/1 [==============================] - 0s 72ms/step\n","1/1 [==============================] - 0s 68ms/step\n","1/1 [==============================] - 0s 64ms/step\n","1/1 [==============================] - 0s 64ms/step\n","1/1 [==============================] - 0s 65ms/step\n","1/1 [==============================] - 0s 62ms/step\n","1/1 [==============================] - 0s 69ms/step\n","1/1 [==============================] - 0s 69ms/step\n","1/1 [==============================] - 0s 66ms/step\n","1/1 [==============================] - 0s 66ms/step\n","1/1 [==============================] - 0s 69ms/step\n","1/1 [==============================] - 0s 69ms/step\n","1/1 [==============================] - 0s 63ms/step\n","1/1 [==============================] - 0s 70ms/step\n","1/1 [==============================] - 0s 65ms/step\n","1/1 [==============================] - 0s 65ms/step\n","1/1 [==============================] - 0s 66ms/step\n","1/1 [==============================] - 0s 69ms/step\n","1/1 [==============================] - 0s 66ms/step\n","1/1 [==============================] - 0s 73ms/step\n","1/1 [==============================] - 0s 66ms/step\n","1/1 [==============================] - 0s 72ms/step\n","1/1 [==============================] - 0s 65ms/step\n","1/1 [==============================] - 0s 67ms/step\n","1/1 [==============================] - 0s 69ms/step\n","1/1 [==============================] - 0s 71ms/step\n","1/1 [==============================] - 0s 67ms/step\n","1/1 [==============================] - 0s 68ms/step\n","1/1 [==============================] - 0s 73ms/step\n","1/1 [==============================] - 0s 68ms/step\n","1/1 [==============================] - 0s 69ms/step\n","1/1 [==============================] - 0s 64ms/step\n","1/1 [==============================] - 0s 67ms/step\n","1/1 [==============================] - 0s 68ms/step\n","1/1 [==============================] - 0s 74ms/step\n","1/1 [==============================] - 0s 76ms/step\n","1/1 [==============================] - 0s 69ms/step\n","1/1 [==============================] - 0s 71ms/step\n","1/1 [==============================] - 0s 68ms/step\n","1/1 [==============================] - 0s 74ms/step\n","1/1 [==============================] - 0s 66ms/step\n","1/1 [==============================] - 0s 72ms/step\n","1/1 [==============================] - 0s 72ms/step\n","1/1 [==============================] - 0s 69ms/step\n","1/1 [==============================] - 0s 73ms/step\n","1/1 [==============================] - 0s 73ms/step\n","1/1 [==============================] - 0s 73ms/step\n","1/1 [==============================] - 0s 71ms/step\n","1/1 [==============================] - 0s 73ms/step\n","1/1 [==============================] - 0s 74ms/step\n","1/1 [==============================] - 0s 83ms/step\n","1/1 [==============================] - 0s 73ms/step\n","1/1 [==============================] - 0s 76ms/step\n","1/1 [==============================] - 0s 77ms/step\n","1/1 [==============================] - 0s 75ms/step\n","1/1 [==============================] - 0s 73ms/step\n","1/1 [==============================] - 0s 76ms/step\n","1/1 [==============================] - 0s 81ms/step\n","1/1 [==============================] - 0s 70ms/step\n","1/1 [==============================] - 0s 73ms/step\n","1/1 [==============================] - 0s 78ms/step\n","1/1 [==============================] - 0s 77ms/step\n","1/1 [==============================] - 0s 77ms/step\n","1/1 [==============================] - 0s 75ms/step\n","[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 1. 1. 1. 1. 1. 1.\n"," 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n"," 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n"," 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n"," 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n"," 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n"," 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n"," 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n"," 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n","0.6875\n","1/1 [==============================] - 0s 362ms/step\n","1/1 [==============================] - 0s 65ms/step\n","1/1 [==============================] - 0s 69ms/step\n","1/1 [==============================] - 0s 69ms/step\n","1/1 [==============================] - 0s 66ms/step\n","1/1 [==============================] - 0s 66ms/step\n","1/1 [==============================] - 0s 65ms/step\n","1/1 [==============================] - 0s 66ms/step\n","1/1 [==============================] - 0s 68ms/step\n","1/1 [==============================] - 0s 63ms/step\n","1/1 [==============================] - 0s 66ms/step\n","1/1 [==============================] - 0s 67ms/step\n","1/1 [==============================] - 0s 67ms/step\n","1/1 [==============================] - 0s 64ms/step\n","1/1 [==============================] - 0s 65ms/step\n","1/1 [==============================] - 0s 63ms/step\n","1/1 [==============================] - 0s 67ms/step\n","1/1 [==============================] - 0s 67ms/step\n","1/1 [==============================] - 0s 67ms/step\n","1/1 [==============================] - 0s 72ms/step\n","1/1 [==============================] - 0s 70ms/step\n","1/1 [==============================] - 0s 65ms/step\n","1/1 [==============================] - 0s 66ms/step\n","1/1 [==============================] - 0s 68ms/step\n","1/1 [==============================] - 0s 71ms/step\n","1/1 [==============================] - 0s 67ms/step\n","1/1 [==============================] - 0s 66ms/step\n","1/1 [==============================] - 0s 69ms/step\n","1/1 [==============================] - 0s 62ms/step\n","1/1 [==============================] - 0s 69ms/step\n","1/1 [==============================] - 0s 66ms/step\n","1/1 [==============================] - 0s 66ms/step\n","1/1 [==============================] - 0s 66ms/step\n","1/1 [==============================] - 0s 66ms/step\n","1/1 [==============================] - 0s 65ms/step\n","1/1 [==============================] - 0s 69ms/step\n","1/1 [==============================] - 0s 65ms/step\n","1/1 [==============================] - 0s 70ms/step\n","1/1 [==============================] - 0s 65ms/step\n","1/1 [==============================] - 0s 64ms/step\n","1/1 [==============================] - 0s 63ms/step\n","1/1 [==============================] - 0s 67ms/step\n","1/1 [==============================] - 0s 64ms/step\n","1/1 [==============================] - 0s 68ms/step\n","1/1 [==============================] - 0s 68ms/step\n","1/1 [==============================] - 0s 70ms/step\n","1/1 [==============================] - 0s 69ms/step\n","1/1 [==============================] - 0s 69ms/step\n","1/1 [==============================] - 0s 68ms/step\n","1/1 [==============================] - 0s 66ms/step\n","1/1 [==============================] - 0s 64ms/step\n","1/1 [==============================] - 0s 67ms/step\n","1/1 [==============================] - 0s 66ms/step\n","1/1 [==============================] - 0s 67ms/step\n","1/1 [==============================] - 0s 69ms/step\n","1/1 [==============================] - 0s 67ms/step\n","1/1 [==============================] - 0s 67ms/step\n","1/1 [==============================] - 0s 69ms/step\n","1/1 [==============================] - 0s 67ms/step\n","1/1 [==============================] - 0s 71ms/step\n","1/1 [==============================] - 0s 68ms/step\n","1/1 [==============================] - 0s 68ms/step\n","1/1 [==============================] - 0s 69ms/step\n","1/1 [==============================] - 0s 63ms/step\n","1/1 [==============================] - 0s 72ms/step\n","1/1 [==============================] - 0s 68ms/step\n","1/1 [==============================] - 0s 69ms/step\n","1/1 [==============================] - 0s 67ms/step\n","1/1 [==============================] - 0s 70ms/step\n","1/1 [==============================] - 0s 69ms/step\n","1/1 [==============================] - 0s 67ms/step\n","1/1 [==============================] - 0s 66ms/step\n","1/1 [==============================] - 0s 67ms/step\n","1/1 [==============================] - 0s 67ms/step\n","1/1 [==============================] - 0s 67ms/step\n","1/1 [==============================] - 0s 67ms/step\n","1/1 [==============================] - 0s 68ms/step\n","1/1 [==============================] - 0s 67ms/step\n","1/1 [==============================] - 0s 69ms/step\n","1/1 [==============================] - 0s 73ms/step\n","1/1 [==============================] - 0s 69ms/step\n","1/1 [==============================] - 0s 66ms/step\n","1/1 [==============================] - 0s 72ms/step\n","1/1 [==============================] - 0s 79ms/step\n","1/1 [==============================] - 0s 73ms/step\n","1/1 [==============================] - 0s 69ms/step\n","1/1 [==============================] - 0s 68ms/step\n","1/1 [==============================] - 0s 70ms/step\n","1/1 [==============================] - 0s 74ms/step\n","1/1 [==============================] - 0s 71ms/step\n","1/1 [==============================] - 0s 73ms/step\n","1/1 [==============================] - 0s 76ms/step\n","1/1 [==============================] - 0s 69ms/step\n","1/1 [==============================] - 0s 72ms/step\n","1/1 [==============================] - 0s 83ms/step\n","1/1 [==============================] - 0s 69ms/step\n","1/1 [==============================] - 0s 69ms/step\n","1/1 [==============================] - 0s 70ms/step\n","1/1 [==============================] - 0s 76ms/step\n","1/1 [==============================] - 0s 76ms/step\n","1/1 [==============================] - 0s 83ms/step\n","1/1 [==============================] - 0s 71ms/step\n","1/1 [==============================] - 0s 85ms/step\n","1/1 [==============================] - 0s 93ms/step\n","1/1 [==============================] - 0s 75ms/step\n","1/1 [==============================] - 0s 72ms/step\n","1/1 [==============================] - 0s 68ms/step\n","1/1 [==============================] - 0s 66ms/step\n","1/1 [==============================] - 0s 92ms/step\n","1/1 [==============================] - 0s 73ms/step\n","1/1 [==============================] - 0s 69ms/step\n","1/1 [==============================] - 0s 64ms/step\n","1/1 [==============================] - 0s 68ms/step\n","1/1 [==============================] - 0s 68ms/step\n","1/1 [==============================] - 0s 102ms/step\n","1/1 [==============================] - 0s 65ms/step\n","1/1 [==============================] - 0s 67ms/step\n","1/1 [==============================] - 0s 70ms/step\n","1/1 [==============================] - 0s 67ms/step\n","1/1 [==============================] - 0s 66ms/step\n","1/1 [==============================] - 0s 66ms/step\n","1/1 [==============================] - 0s 66ms/step\n","1/1 [==============================] - 0s 67ms/step\n","1/1 [==============================] - 0s 65ms/step\n","1/1 [==============================] - 0s 66ms/step\n","1/1 [==============================] - 0s 64ms/step\n","1/1 [==============================] - 0s 67ms/step\n","1/1 [==============================] - 0s 70ms/step\n","1/1 [==============================] - 0s 66ms/step\n","1/1 [==============================] - 0s 70ms/step\n","1/1 [==============================] - 0s 69ms/step\n","1/1 [==============================] - 0s 77ms/step\n","1/1 [==============================] - 0s 70ms/step\n","1/1 [==============================] - 0s 67ms/step\n","1/1 [==============================] - 0s 68ms/step\n","1/1 [==============================] - 0s 68ms/step\n","1/1 [==============================] - 0s 72ms/step\n","1/1 [==============================] - 0s 71ms/step\n","1/1 [==============================] - 0s 66ms/step\n","1/1 [==============================] - 0s 68ms/step\n","1/1 [==============================] - 0s 70ms/step\n","1/1 [==============================] - 0s 66ms/step\n","1/1 [==============================] - 0s 67ms/step\n","1/1 [==============================] - 0s 66ms/step\n","1/1 [==============================] - 0s 73ms/step\n","1/1 [==============================] - 0s 67ms/step\n","1/1 [==============================] - 0s 72ms/step\n","1/1 [==============================] - 0s 66ms/step\n","1/1 [==============================] - 0s 68ms/step\n","1/1 [==============================] - 0s 69ms/step\n","1/1 [==============================] - 0s 77ms/step\n","1/1 [==============================] - 0s 65ms/step\n","1/1 [==============================] - 0s 71ms/step\n","1/1 [==============================] - 0s 68ms/step\n","1/1 [==============================] - 0s 67ms/step\n","1/1 [==============================] - 0s 73ms/step\n","1/1 [==============================] - 0s 64ms/step\n","1/1 [==============================] - 0s 66ms/step\n","1/1 [==============================] - 0s 64ms/step\n","1/1 [==============================] - 0s 70ms/step\n","1/1 [==============================] - 0s 69ms/step\n","1/1 [==============================] - 0s 70ms/step\n","1/1 [==============================] - 0s 70ms/step\n","1/1 [==============================] - 0s 70ms/step\n","1/1 [==============================] - 0s 64ms/step\n","1/1 [==============================] - 0s 71ms/step\n","1/1 [==============================] - 0s 67ms/step\n","1/1 [==============================] - 0s 69ms/step\n","1/1 [==============================] - 0s 70ms/step\n","1/1 [==============================] - 0s 73ms/step\n","1/1 [==============================] - 0s 68ms/step\n","1/1 [==============================] - 0s 68ms/step\n","1/1 [==============================] - 0s 67ms/step\n","1/1 [==============================] - 0s 66ms/step\n","1/1 [==============================] - 0s 64ms/step\n","1/1 [==============================] - 0s 68ms/step\n","1/1 [==============================] - 0s 70ms/step\n","1/1 [==============================] - 0s 66ms/step\n","1/1 [==============================] - 0s 67ms/step\n","1/1 [==============================] - 0s 68ms/step\n","1/1 [==============================] - 0s 66ms/step\n","1/1 [==============================] - 0s 64ms/step\n","1/1 [==============================] - 0s 66ms/step\n","1/1 [==============================] - 0s 70ms/step\n","1/1 [==============================] - 0s 70ms/step\n","1/1 [==============================] - 0s 72ms/step\n","1/1 [==============================] - 0s 75ms/step\n","1/1 [==============================] - 0s 79ms/step\n","1/1 [==============================] - 0s 73ms/step\n","1/1 [==============================] - 0s 74ms/step\n","1/1 [==============================] - 0s 71ms/step\n","1/1 [==============================] - 0s 73ms/step\n","1/1 [==============================] - 0s 67ms/step\n","1/1 [==============================] - 0s 70ms/step\n","1/1 [==============================] - 0s 73ms/step\n","1/1 [==============================] - 0s 80ms/step\n","1/1 [==============================] - 0s 67ms/step\n","1/1 [==============================] - 0s 72ms/step\n","1/1 [==============================] - 0s 75ms/step\n","1/1 [==============================] - 0s 73ms/step\n","1/1 [==============================] - 0s 71ms/step\n","1/1 [==============================] - 0s 82ms/step\n","1/1 [==============================] - 0s 74ms/step\n","1/1 [==============================] - 0s 74ms/step\n","1/1 [==============================] - 0s 81ms/step\n","1/1 [==============================] - 0s 69ms/step\n","1/1 [==============================] - 0s 69ms/step\n","1/1 [==============================] - 0s 70ms/step\n","1/1 [==============================] - 0s 70ms/step\n","1/1 [==============================] - 0s 72ms/step\n","1/1 [==============================] - 0s 68ms/step\n","1/1 [==============================] - 0s 66ms/step\n","1/1 [==============================] - 0s 65ms/step\n","1/1 [==============================] - 0s 68ms/step\n","1/1 [==============================] - 0s 71ms/step\n","1/1 [==============================] - 0s 67ms/step\n","1/1 [==============================] - 0s 66ms/step\n","1/1 [==============================] - 0s 71ms/step\n","1/1 [==============================] - 0s 68ms/step\n","1/1 [==============================] - 0s 69ms/step\n","1/1 [==============================] - 0s 72ms/step\n","1/1 [==============================] - 0s 70ms/step\n","1/1 [==============================] - 0s 65ms/step\n","1/1 [==============================] - 0s 66ms/step\n","1/1 [==============================] - 0s 71ms/step\n","1/1 [==============================] - 0s 64ms/step\n","1/1 [==============================] - 0s 68ms/step\n","1/1 [==============================] - 0s 66ms/step\n","1/1 [==============================] - 0s 67ms/step\n","1/1 [==============================] - 0s 73ms/step\n","1/1 [==============================] - 0s 69ms/step\n","1/1 [==============================] - 0s 69ms/step\n","1/1 [==============================] - 0s 73ms/step\n","1/1 [==============================] - 0s 69ms/step\n","1/1 [==============================] - 0s 70ms/step\n","1/1 [==============================] - 0s 66ms/step\n","1/1 [==============================] - 0s 72ms/step\n","1/1 [==============================] - 0s 68ms/step\n","1/1 [==============================] - 0s 67ms/step\n","1/1 [==============================] - 0s 68ms/step\n","1/1 [==============================] - 0s 67ms/step\n","1/1 [==============================] - 0s 67ms/step\n","1/1 [==============================] - 0s 66ms/step\n","1/1 [==============================] - 0s 62ms/step\n","1/1 [==============================] - 0s 63ms/step\n","1/1 [==============================] - 0s 69ms/step\n","1/1 [==============================] - 0s 66ms/step\n","1/1 [==============================] - 0s 72ms/step\n","1/1 [==============================] - 0s 72ms/step\n","1/1 [==============================] - 0s 68ms/step\n","1/1 [==============================] - 0s 68ms/step\n","1/1 [==============================] - 0s 64ms/step\n","1/1 [==============================] - 0s 67ms/step\n","1/1 [==============================] - 0s 72ms/step\n","1/1 [==============================] - 0s 68ms/step\n","1/1 [==============================] - 0s 67ms/step\n","1/1 [==============================] - 0s 66ms/step\n","1/1 [==============================] - 0s 69ms/step\n","1/1 [==============================] - 0s 71ms/step\n","1/1 [==============================] - 0s 69ms/step\n","1/1 [==============================] - 0s 67ms/step\n","1/1 [==============================] - 0s 67ms/step\n","1/1 [==============================] - 0s 69ms/step\n","1/1 [==============================] - 0s 73ms/step\n","1/1 [==============================] - 0s 66ms/step\n","1/1 [==============================] - 0s 65ms/step\n","1/1 [==============================] - 0s 68ms/step\n","1/1 [==============================] - 0s 75ms/step\n","1/1 [==============================] - 0s 68ms/step\n","1/1 [==============================] - 0s 69ms/step\n","1/1 [==============================] - 0s 65ms/step\n","1/1 [==============================] - 0s 71ms/step\n","1/1 [==============================] - 0s 68ms/step\n","1/1 [==============================] - 0s 68ms/step\n","1/1 [==============================] - 0s 68ms/step\n","1/1 [==============================] - 0s 68ms/step\n","1/1 [==============================] - 0s 67ms/step\n","1/1 [==============================] - 0s 65ms/step\n","1/1 [==============================] - 0s 69ms/step\n","1/1 [==============================] - 0s 75ms/step\n","1/1 [==============================] - 0s 64ms/step\n","1/1 [==============================] - 0s 66ms/step\n","1/1 [==============================] - 0s 71ms/step\n","1/1 [==============================] - 0s 67ms/step\n","1/1 [==============================] - 0s 67ms/step\n","1/1 [==============================] - 0s 68ms/step\n","1/1 [==============================] - 0s 68ms/step\n","1/1 [==============================] - 0s 67ms/step\n","[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 3. 3. 3. 3. 3. 3.\n"," 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n"," 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1.\n"," 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n","0.4375\n","1/1 [==============================] - 0s 372ms/step\n","1/1 [==============================] - 0s 73ms/step\n","1/1 [==============================] - 0s 73ms/step\n","1/1 [==============================] - 0s 71ms/step\n","1/1 [==============================] - 0s 74ms/step\n","1/1 [==============================] - 0s 72ms/step\n","1/1 [==============================] - 0s 77ms/step\n","1/1 [==============================] - 0s 70ms/step\n","1/1 [==============================] - 0s 69ms/step\n","1/1 [==============================] - 0s 72ms/step\n","1/1 [==============================] - 0s 72ms/step\n","1/1 [==============================] - 0s 74ms/step\n","1/1 [==============================] - 0s 73ms/step\n","1/1 [==============================] - 0s 78ms/step\n","1/1 [==============================] - 0s 72ms/step\n","1/1 [==============================] - 0s 70ms/step\n","1/1 [==============================] - 0s 72ms/step\n","1/1 [==============================] - 0s 65ms/step\n","1/1 [==============================] - 0s 70ms/step\n","1/1 [==============================] - 0s 66ms/step\n","1/1 [==============================] - 0s 66ms/step\n","1/1 [==============================] - 0s 68ms/step\n","1/1 [==============================] - 0s 71ms/step\n","1/1 [==============================] - 0s 70ms/step\n","1/1 [==============================] - 0s 75ms/step\n","1/1 [==============================] - 0s 68ms/step\n","1/1 [==============================] - 0s 71ms/step\n","1/1 [==============================] - 0s 67ms/step\n","1/1 [==============================] - 0s 69ms/step\n","1/1 [==============================] - 0s 68ms/step\n","1/1 [==============================] - 0s 75ms/step\n","1/1 [==============================] - 0s 71ms/step\n","1/1 [==============================] - 0s 69ms/step\n","1/1 [==============================] - 0s 73ms/step\n","1/1 [==============================] - 0s 72ms/step\n","1/1 [==============================] - 0s 66ms/step\n","1/1 [==============================] - 0s 66ms/step\n","1/1 [==============================] - 0s 72ms/step\n","1/1 [==============================] - 0s 70ms/step\n","1/1 [==============================] - 0s 65ms/step\n","1/1 [==============================] - 0s 68ms/step\n","1/1 [==============================] - 0s 71ms/step\n","1/1 [==============================] - 0s 66ms/step\n","1/1 [==============================] - 0s 68ms/step\n","1/1 [==============================] - 0s 73ms/step\n","1/1 [==============================] - 0s 70ms/step\n","1/1 [==============================] - 0s 72ms/step\n","1/1 [==============================] - 0s 68ms/step\n","1/1 [==============================] - 0s 67ms/step\n","1/1 [==============================] - 0s 67ms/step\n","1/1 [==============================] - 0s 66ms/step\n","1/1 [==============================] - 0s 69ms/step\n","1/1 [==============================] - 0s 68ms/step\n","1/1 [==============================] - 0s 69ms/step\n","1/1 [==============================] - 0s 70ms/step\n","1/1 [==============================] - 0s 68ms/step\n","1/1 [==============================] - 0s 68ms/step\n","1/1 [==============================] - 0s 67ms/step\n","1/1 [==============================] - 0s 65ms/step\n","1/1 [==============================] - 0s 68ms/step\n","1/1 [==============================] - 0s 71ms/step\n","1/1 [==============================] - 0s 71ms/step\n","1/1 [==============================] - 0s 67ms/step\n","1/1 [==============================] - 0s 70ms/step\n","1/1 [==============================] - 0s 67ms/step\n","1/1 [==============================] - 0s 74ms/step\n","1/1 [==============================] - 0s 68ms/step\n","1/1 [==============================] - 0s 72ms/step\n","1/1 [==============================] - 0s 68ms/step\n","1/1 [==============================] - 0s 73ms/step\n","1/1 [==============================] - 0s 75ms/step\n","1/1 [==============================] - 0s 68ms/step\n","1/1 [==============================] - 0s 65ms/step\n","1/1 [==============================] - 0s 66ms/step\n","1/1 [==============================] - 0s 65ms/step\n","1/1 [==============================] - 0s 69ms/step\n","1/1 [==============================] - 0s 69ms/step\n","1/1 [==============================] - 0s 69ms/step\n","1/1 [==============================] - 0s 66ms/step\n","1/1 [==============================] - 0s 70ms/step\n","1/1 [==============================] - 0s 63ms/step\n","1/1 [==============================] - 0s 70ms/step\n","1/1 [==============================] - 0s 67ms/step\n","1/1 [==============================] - 0s 70ms/step\n","1/1 [==============================] - 0s 69ms/step\n","1/1 [==============================] - 0s 66ms/step\n","1/1 [==============================] - 0s 71ms/step\n","1/1 [==============================] - 0s 71ms/step\n","1/1 [==============================] - 0s 72ms/step\n","1/1 [==============================] - 0s 66ms/step\n","1/1 [==============================] - 0s 66ms/step\n","1/1 [==============================] - 0s 66ms/step\n","1/1 [==============================] - 0s 63ms/step\n","1/1 [==============================] - 0s 65ms/step\n","1/1 [==============================] - 0s 69ms/step\n","1/1 [==============================] - 0s 80ms/step\n","1/1 [==============================] - 0s 77ms/step\n","1/1 [==============================] - 0s 71ms/step\n","1/1 [==============================] - 0s 69ms/step\n","1/1 [==============================] - 0s 71ms/step\n","1/1 [==============================] - 0s 67ms/step\n","1/1 [==============================] - 0s 70ms/step\n","1/1 [==============================] - 0s 75ms/step\n","1/1 [==============================] - 0s 72ms/step\n","1/1 [==============================] - 0s 80ms/step\n","1/1 [==============================] - 0s 71ms/step\n","1/1 [==============================] - 0s 68ms/step\n","1/1 [==============================] - 0s 69ms/step\n","1/1 [==============================] - 0s 71ms/step\n","1/1 [==============================] - 0s 74ms/step\n","1/1 [==============================] - 0s 75ms/step\n","1/1 [==============================] - 0s 72ms/step\n","1/1 [==============================] - 0s 73ms/step\n","1/1 [==============================] - 0s 76ms/step\n","1/1 [==============================] - 0s 74ms/step\n","1/1 [==============================] - 0s 70ms/step\n","1/1 [==============================] - 0s 75ms/step\n","1/1 [==============================] - 0s 75ms/step\n","1/1 [==============================] - 0s 74ms/step\n","1/1 [==============================] - 0s 71ms/step\n","1/1 [==============================] - 0s 77ms/step\n","1/1 [==============================] - 0s 65ms/step\n","1/1 [==============================] - 0s 65ms/step\n","1/1 [==============================] - 0s 66ms/step\n","1/1 [==============================] - 0s 65ms/step\n","1/1 [==============================] - 0s 73ms/step\n","1/1 [==============================] - 0s 69ms/step\n","1/1 [==============================] - 0s 70ms/step\n","1/1 [==============================] - 0s 72ms/step\n","1/1 [==============================] - 0s 70ms/step\n","1/1 [==============================] - 0s 64ms/step\n","1/1 [==============================] - 0s 63ms/step\n","1/1 [==============================] - 0s 64ms/step\n","1/1 [==============================] - 0s 72ms/step\n","1/1 [==============================] - 0s 64ms/step\n","1/1 [==============================] - 0s 67ms/step\n","1/1 [==============================] - 0s 68ms/step\n","1/1 [==============================] - 0s 64ms/step\n","1/1 [==============================] - 0s 63ms/step\n","1/1 [==============================] - 0s 68ms/step\n","1/1 [==============================] - 0s 67ms/step\n","1/1 [==============================] - 0s 72ms/step\n","1/1 [==============================] - 0s 65ms/step\n","1/1 [==============================] - 0s 68ms/step\n","1/1 [==============================] - 0s 70ms/step\n","1/1 [==============================] - 0s 71ms/step\n","1/1 [==============================] - 0s 67ms/step\n","1/1 [==============================] - 0s 68ms/step\n","1/1 [==============================] - 0s 66ms/step\n","1/1 [==============================] - 0s 65ms/step\n","1/1 [==============================] - 0s 67ms/step\n","1/1 [==============================] - 0s 63ms/step\n","1/1 [==============================] - 0s 68ms/step\n","1/1 [==============================] - 0s 69ms/step\n","1/1 [==============================] - 0s 68ms/step\n","1/1 [==============================] - 0s 70ms/step\n","1/1 [==============================] - 0s 69ms/step\n","1/1 [==============================] - 0s 66ms/step\n","1/1 [==============================] - 0s 69ms/step\n","1/1 [==============================] - 0s 65ms/step\n","1/1 [==============================] - 0s 67ms/step\n","1/1 [==============================] - 0s 65ms/step\n","1/1 [==============================] - 0s 71ms/step\n","1/1 [==============================] - 0s 65ms/step\n","1/1 [==============================] - 0s 65ms/step\n","1/1 [==============================] - 0s 65ms/step\n","1/1 [==============================] - 0s 65ms/step\n","1/1 [==============================] - 0s 66ms/step\n","1/1 [==============================] - 0s 65ms/step\n","1/1 [==============================] - 0s 65ms/step\n","1/1 [==============================] - 0s 69ms/step\n","1/1 [==============================] - 0s 65ms/step\n","1/1 [==============================] - 0s 69ms/step\n","1/1 [==============================] - 0s 68ms/step\n","1/1 [==============================] - 0s 68ms/step\n","1/1 [==============================] - 0s 66ms/step\n","1/1 [==============================] - 0s 64ms/step\n","1/1 [==============================] - 0s 62ms/step\n","1/1 [==============================] - 0s 66ms/step\n","1/1 [==============================] - 0s 67ms/step\n","1/1 [==============================] - 0s 63ms/step\n","1/1 [==============================] - 0s 68ms/step\n","1/1 [==============================] - 0s 66ms/step\n","1/1 [==============================] - 0s 73ms/step\n","1/1 [==============================] - 0s 64ms/step\n","1/1 [==============================] - 0s 62ms/step\n","1/1 [==============================] - 0s 68ms/step\n","1/1 [==============================] - 0s 67ms/step\n","1/1 [==============================] - 0s 67ms/step\n","1/1 [==============================] - 0s 66ms/step\n","1/1 [==============================] - 0s 65ms/step\n","1/1 [==============================] - 0s 64ms/step\n","1/1 [==============================] - 0s 63ms/step\n","1/1 [==============================] - 0s 67ms/step\n","1/1 [==============================] - 0s 66ms/step\n","1/1 [==============================] - 0s 68ms/step\n","1/1 [==============================] - 0s 66ms/step\n","1/1 [==============================] - 0s 65ms/step\n","1/1 [==============================] - 0s 64ms/step\n","1/1 [==============================] - 0s 68ms/step\n","1/1 [==============================] - 0s 69ms/step\n","1/1 [==============================] - 0s 64ms/step\n","1/1 [==============================] - 0s 69ms/step\n","1/1 [==============================] - 0s 66ms/step\n","1/1 [==============================] - 0s 73ms/step\n","1/1 [==============================] - 0s 71ms/step\n","1/1 [==============================] - 0s 68ms/step\n","1/1 [==============================] - 0s 70ms/step\n","1/1 [==============================] - 0s 71ms/step\n","1/1 [==============================] - 0s 70ms/step\n","1/1 [==============================] - 0s 73ms/step\n","1/1 [==============================] - 0s 79ms/step\n","1/1 [==============================] - 0s 72ms/step\n","1/1 [==============================] - 0s 68ms/step\n","1/1 [==============================] - 0s 68ms/step\n","1/1 [==============================] - 0s 83ms/step\n","1/1 [==============================] - 0s 70ms/step\n","1/1 [==============================] - 0s 74ms/step\n","1/1 [==============================] - 0s 75ms/step\n","1/1 [==============================] - 0s 72ms/step\n","1/1 [==============================] - 0s 69ms/step\n","1/1 [==============================] - 0s 79ms/step\n","1/1 [==============================] - 0s 69ms/step\n","1/1 [==============================] - 0s 69ms/step\n","1/1 [==============================] - 0s 70ms/step\n","1/1 [==============================] - 0s 69ms/step\n","1/1 [==============================] - 0s 69ms/step\n","1/1 [==============================] - 0s 69ms/step\n","1/1 [==============================] - 0s 74ms/step\n","1/1 [==============================] - 0s 66ms/step\n","1/1 [==============================] - 0s 67ms/step\n","1/1 [==============================] - 0s 70ms/step\n","1/1 [==============================] - 0s 68ms/step\n","1/1 [==============================] - 0s 72ms/step\n","1/1 [==============================] - 0s 65ms/step\n","1/1 [==============================] - 0s 66ms/step\n","1/1 [==============================] - 0s 64ms/step\n","1/1 [==============================] - 0s 69ms/step\n","1/1 [==============================] - 0s 62ms/step\n","1/1 [==============================] - 0s 69ms/step\n","1/1 [==============================] - 0s 64ms/step\n","1/1 [==============================] - 0s 71ms/step\n","1/1 [==============================] - 0s 68ms/step\n","1/1 [==============================] - 0s 67ms/step\n","1/1 [==============================] - 0s 67ms/step\n","1/1 [==============================] - 0s 66ms/step\n","1/1 [==============================] - 0s 67ms/step\n","1/1 [==============================] - 0s 66ms/step\n","1/1 [==============================] - 0s 69ms/step\n","1/1 [==============================] - 0s 71ms/step\n","1/1 [==============================] - 0s 73ms/step\n","1/1 [==============================] - 0s 73ms/step\n","1/1 [==============================] - 0s 73ms/step\n","1/1 [==============================] - 0s 74ms/step\n","1/1 [==============================] - 0s 79ms/step\n","1/1 [==============================] - 0s 72ms/step\n","1/1 [==============================] - 0s 77ms/step\n","1/1 [==============================] - 0s 77ms/step\n","1/1 [==============================] - 0s 78ms/step\n","1/1 [==============================] - 0s 70ms/step\n","1/1 [==============================] - 0s 74ms/step\n","1/1 [==============================] - 0s 72ms/step\n","1/1 [==============================] - 0s 73ms/step\n","1/1 [==============================] - 0s 74ms/step\n","1/1 [==============================] - 0s 79ms/step\n","1/1 [==============================] - 0s 74ms/step\n","1/1 [==============================] - 0s 79ms/step\n","1/1 [==============================] - 0s 70ms/step\n","1/1 [==============================] - 0s 70ms/step\n","1/1 [==============================] - 0s 68ms/step\n","1/1 [==============================] - 0s 70ms/step\n","1/1 [==============================] - 0s 68ms/step\n","1/1 [==============================] - 0s 81ms/step\n","1/1 [==============================] - 0s 76ms/step\n","1/1 [==============================] - 0s 69ms/step\n","1/1 [==============================] - 0s 70ms/step\n","1/1 [==============================] - 0s 71ms/step\n","1/1 [==============================] - 0s 66ms/step\n","1/1 [==============================] - 0s 74ms/step\n","1/1 [==============================] - 0s 71ms/step\n","1/1 [==============================] - 0s 73ms/step\n","1/1 [==============================] - 0s 72ms/step\n","1/1 [==============================] - 0s 72ms/step\n","1/1 [==============================] - 0s 68ms/step\n","1/1 [==============================] - 0s 67ms/step\n","1/1 [==============================] - 0s 67ms/step\n","1/1 [==============================] - 0s 66ms/step\n","1/1 [==============================] - 0s 74ms/step\n","[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1.\n"," 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n"," 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 3. 1. 1.\n"," 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 3. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n"," 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n"," 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 3. 3. 3. 3. 3. 3.\n"," 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3.\n"," 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3.]\n","0.5\n"]}]}]}